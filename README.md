## NPMAI-RAG-API-Pipeline

A powerful **FastAPI-based multi-modal ingestion system** that processes PDFs, scanned documents, images, videos, YouTube links, and text files â€” then optionally performs semantic retrieval using FAISS + HuggingFace embeddings and refines answers using an LLM (Ollama via NPMAI).

---

## ğŸš€ Features

- ğŸ“„ Extract text from searchable PDFs
- ğŸ–¨ï¸ OCR for scanned PDFs
- ğŸ–¼ï¸ Image OCR (Tesseract + OpenCV preprocessing)
- ğŸ¥ Local video speech-to-text (Whisper)
- ğŸ“º YouTube video transcription (yt-dlp + Whisper)
- ğŸ“ƒ Plain text processing
- ğŸ§  FAISS vector database creation & loading
- ğŸ” Semantic similarity search
- â™»ï¸ Iterative refinement using LLM (Ollama)
- ğŸ—‚ Automatic ingestion routing based on file type

---

## ğŸ— Architecture Overview

```
Client Request
      â†“
/ingestion Endpoint
      â†“
File Type Detection
      â†“
Text Extraction (PDF/OCR/Video/etc.)
      â†“
Optional Vector DB Retrieval (FAISS)
      â†“
Refinement via LLM
      â†“
Final Response
```

---

## ğŸ“Œ API Endpoints

### Health Check
```
GET /
```
Returns:
```json
{ "ok": true }
```

---

### Main Ingestion Endpoint

```
POST /ingestion
```

### Supported Inputs:
- `file` â†’ Upload file (pdf, txt, mp4, jpg, png, etc.)
- `query` â†’ Optional semantic query
- `DB_PATH` â†’ Path to vector database
- `link` â†’ YouTube link
- `output_path` â†’ Download location for video
- `temperature` â†’ LLM temperature
- `model` â†’ Ollama model name

---

## ğŸ“‚ Supported File Types

| Type | Processing Method |
|------|-------------------|
| PDF (text-based) | PyMuPDF |
| PDF (scanned) | pdf2image + Tesseract |
| Image | OpenCV + Tesseract |
| TXT | Direct read |
| MP4 | Whisper transcription |
| YouTube | yt-dlp + Whisper |

---

## ğŸ” Retrieval Pipeline

If `query` and `DB_PATH` are provided:

1. Check if FAISS DB exists
2. If yes â†’ Load and perform similarity search
3. If no â†’ Create embeddings & save DB
4. Retrieve top 4 chunks
5. Send to LLM refine loop

---

## ğŸ§  Vector Store

- Embeddings: `all-MiniLM-L6-v2`
- Vector DB: FAISS
- Chunk Size: 1000
- Overlap: 200

---

## ğŸ”„ Refinement Logic

For each retrieved chunk:

1. Pass context to LLM
2. Iteratively refine previous answer
3. Return final refined response

---

## ğŸ“¦ Dependencies

Install required packages:

```bash
pip install fastapi uvicorn
pip install langchain langchain-community
pip install faiss-cpu
pip install whisper
pip install moviepy
pip install pytesseract
pip install pdf2image
pip install pymupdf
pip install yt-dlp
pip install opencv-python
pip install pillow
pip install numpy
```

Make sure:

- Tesseract OCR is installed in system
- FFmpeg is installed
- Ollama is running locally

---

## â–¶ï¸ Running the Server

```bash
uvicorn main:app --reload
```

---

## ğŸ§© Example Usage

### Upload a PDF with Retrieval

```
POST /ingestion
Form Data:
file = document.pdf
query = "Summarize key points"
DB_PATH = vector_db
model = llama3
temperature = 0.7
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ uploads/
â”œâ”€â”€ vector_db/
â””â”€â”€ README.md
```

---

## âš ï¸ Notes

- GPU is disabled (`CUDA_VISIBLE_DEVICES=""`)
- Whisper model loads once (thread-safe singleton)
- FAISS uses dangerous deserialization (use trusted DB paths only)
- Temporary audio saved as `temp.wav`

---

## ğŸ”® Future Improvements

- Streaming responses
- Async video processing
- Chunk-level caching
- Background task queue
- Better refine logic
- Support for multiple vector stores
- Docker support

---

## ğŸ›  Tech Stack

- FastAPI
- FAISS
- HuggingFace Embeddings
- Whisper
- OpenCV
- Tesseract OCR
- PyMuPDF
- yt-dlp
- Ollama (NPMAI)

---

## ğŸ“œ License

MIT License

---

## ğŸ’¡ Summary

This system acts as a **universal AI ingestion pipeline** capable of processing multi-modal data and performing intelligent semantic retrieval with LLM refinement.

It can serve as:
- AI document assistant
- Video summarizer
- Research helper
- OCR intelligence engine
- Knowledge base system

---

```
